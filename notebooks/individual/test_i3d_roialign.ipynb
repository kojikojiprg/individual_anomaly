{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8107d1d-435c-439e-aa32-45a500cade45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/raid6/home/yokoyama/research\n"
     ]
    }
   ],
   "source": [
    "%cd /home/yokoyama/research\n",
    "from types import SimpleNamespace\n",
    "import sys\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\".\")\n",
    "from modules.utils.video import Capture, Writer\n",
    "from modules.pose import PoseDataHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23efcc3f-7bba-4f42-9834-968691ac62cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from submodules.i3d.pytorch_i3d import InceptionI3d\n",
    "from torchvision.ops import roi_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78690118",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_num = 1\n",
    "cap = Capture(f\"/raid6/home/yokoyama/datasets/dataset01/train/{video_num:02d}.mp4\")\n",
    "pose_data = PoseDataHandler.load(f\"data/dataset01/train/{video_num:02d}\", [\"bbox\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6487c665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:11<00:00, 11.16s/it]\n"
     ]
    }
   ],
   "source": [
    "def calc_opticalflow(frames):\n",
    "    prev_frame = frames[0]\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_RGB2GRAY)\n",
    "    h, w = prev_frame.shape[:2]\n",
    "    flows = [np.zeros((h, w, 2), dtype=np.float32)]\n",
    "    for frame in tqdm(frames[1:], leave=False):\n",
    "        next_gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, next_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        flows.append(flow)\n",
    "\n",
    "    return np.array(flows)\n",
    "\n",
    "\n",
    "def load_rgb_frames(cap, batch_num, start, length):\n",
    "    batches_frame = []\n",
    "    batches_flow = []\n",
    "    for i in tqdm(range(batch_num)):\n",
    "        frames_raw = []\n",
    "        frames = []\n",
    "        start = start + i\n",
    "        cap.set_pos_frame_count(start)\n",
    "        for j in tqdm(range(start, start + length), leave=False):\n",
    "            img = cap.read()[1]\n",
    "            frames_raw.append(img.copy())\n",
    "            img = (img / 255.) * 2 - 1\n",
    "            frames.append(img)\n",
    "\n",
    "        batches_frame.append(frames)\n",
    "\n",
    "        flows = calc_opticalflow(frames_raw)\n",
    "        batches_flow.append(flows)\n",
    "    return np.array(batches_frame, dtype=np.float32), np.array(batches_flow, dtype=np.float32)\n",
    "\n",
    "\n",
    "batch_num = 1\n",
    "start_frame_num = 1410\n",
    "frame_length = 30\n",
    "frames, flows = load_rgb_frames(cap, batch_num, start_frame_num, frame_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "035f491f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 30, 940, 1280])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channels = 3\n",
    "if in_channels == 3:\n",
    "    tensor = torch.Tensor(frames)\n",
    "elif in_channels == 2:\n",
    "    tensor = torch.Tensor(flows)\n",
    "tensor = torch.permute(tensor, (0, 4, 1, 2, 3))\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "709cafd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"submodules/i3d/models/rgb_imagenet.pt\"\n",
    "# model_path = \"submodules/i3d/models/flow_charades.pt\"\n",
    "i3d = InceptionI3d(in_channels=in_channels)\n",
    "# i3d.replace_logits(157)\n",
    "i3d.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# i3d = InceptionI3d(in_channels=in_channels, final_endpoint=\"Mixed_3b\")\n",
    "# i3d.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "790b4d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 15, 118, 160])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature = i3d.extract_features(tensor)\n",
    "x = tensor\n",
    "for end_point in i3d.VALID_ENDPOINTS:\n",
    "    if end_point in i3d.end_points:\n",
    "        x = i3d._modules[end_point](x)\n",
    "    if end_point == \"Mixed_3b\":\n",
    "        break\n",
    "feature = x\n",
    "feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e053d3d7",
   "metadata": {},
   "source": [
    "torch.Size([2, 256, 15, 118, 160]) 3b  \n",
    "torch.Size([2, 480, 15, 118, 160]) 3c  \n",
    "torch.Size([1, 480, 8, 59, 80]) 4a  \n",
    "torch.Size([1, 512, 8, 59, 80]) 4b  \n",
    "torch.Size([1, 832, 8, 59, 80]) 4f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5822672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxs_all = []\n",
    "for i in range(frame_length):\n",
    "    pose_data_frame = [\n",
    "        data for data in pose_data\n",
    "        if data[\"frame\"] == start_frame_num + i\n",
    "    ]\n",
    "\n",
    "    bboxs = [np.array(data[\"bbox\"]).reshape(2, 2) for data in pose_data_frame]\n",
    "\n",
    "    bboxs = torch.Tensor(np.array(bboxs))\n",
    "    bboxs /= torch.Tensor((w, h))\n",
    "    bboxs *= torch.Tensor((fx, fy))\n",
    "\n",
    "    bboxs_all.append(torch.Tensor(bboxs.reshape(-1, 4)))\n",
    "\n",
    "feature_aligned = roi_align(feature[0], bboxs_all, 3, spatial_scale=fx / w, aligned=False)\n",
    "feature_aligned = feature_aligned.detach().numpy()\n",
    "\n",
    "pids = [data[\"id\"] for data in pose_data_frame]\n",
    "loss_dict = {}\n",
    "for i in range(len(pids) - 1):\n",
    "    for j in range(i + 1, len(pids)):\n",
    "        f1 = feature_aligned[i]\n",
    "        f2 = feature_aligned[j]\n",
    "        loss = (np.square(f1 - f2)).mean()\n",
    "\n",
    "        key = f\"{pids[i]}-{pids[j]}\"\n",
    "        loss_dict[key] = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "956ebb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2-10', '2-6', '2-11', '2-1', '2-4', '10-6', '10-11', '10-1', '10-4', '6-11', '6-1', '6-4', '11-1', '11-4', '1-4'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "abfa7ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-10 0.37568292\n",
      "2-6 0.28895658\n",
      "2-11 0.25893262\n",
      "2-1 0.31032327\n",
      "2-4 0.31060413\n",
      "10-6 0.09601549\n",
      "10-11 0.09754126\n",
      "10-1 0.0953755\n",
      "10-4 0.09537507\n",
      "6-11 0.0012808882\n",
      "6-1 0.00089278305\n",
      "6-4 0.000913571\n",
      "11-1 0.0031828596\n",
      "11-4 0.0032410931\n",
      "1-4 1.4524527e-06\n"
     ]
    }
   ],
   "source": [
    "for key, loss in loss_dict.items():\n",
    "    print(key, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e64af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
